import cover from './cover.png';

export const metadata = {
  emoji: '🧿️',
  title: '传影',
  url: 'https://github.com/idootop/chuanying',
  createAt: '2021-06',
  description: '使用手机相机将物体 “复制/粘贴” 到电脑桌面，所见即所得',
  cover: cover.src,
  pinned: true,
};

# 项目亮点

- 一套 Flutter 代码，多种技术的跨界融合，完美兼容多端。
- 提供了抠图粘贴/文字输入/公式识别 3 种模式

# 幕后花絮

传影，是一次有趣的跨端开发尝试，这个 idea 来自于 clip drop 的原型：https://github.com/cyrildiagne/ar-cutpaste

它融合了 camera，局域网通信，macOS 辅助功能，shell，python，opencv 等多种跨界的技术。
最神奇的地方在于，它可以通过你的手机相机，捕获身边的物体/文字或公式，然后按照在相机中预览的位置和实际大小，将他们“贴”到你的电脑上。

正如前面所提到的，这个项目的实现需要多种跨界技术的融合。

首先，这个项目的 PC 端和移动端都是由 Flutter 开发的，极大的提高了开发效率，尤其是在开发局域网通信协议的过程中，两端可以共用一份代码。

然后，为了实现在 PC 端指定位置输入文字的目的，我又使用 swift 通过 flutter channel 开发了一个 macOS 插件，用来模拟鼠标的点击和键盘的输入动作（类似远程控制电脑所用到的技术）。

有趣的是，这个插件大部分的开发过程，是我在从上海回山东的高铁上完成的。

最后还剩下传影的核心：如何根据相机预览的画面，找到其和电脑桌面坐标之间的映射关系？

底层原理是通过 shell 调用 python 中的 opencv 库，分析相机拍到的屏幕图像，和对应时刻屏幕截图之间的相似点，来定位手机照片中的物理坐标和电脑屏幕坐标之前的映射关系。

然后我在原来的 screenpoint 只提供中心点坐标的基础上，将其扩展到了屏幕四个边角点的坐标位置，这样就有了整个屏幕的宽高信息和位置映射，实现了更精准的位置和大小匹配。
